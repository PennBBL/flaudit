---
title: 'FLAUDIT: Flywheel Project Audit'
output:
  html_document:
    df_print: paged
    
params:
  project_name: "gear_testing"
  attachments_csv: "data/attachments.csv"
  seqinfo_csv: "data/seqinfo.csv"
  bids_csv: "data/bids.csv"
  workflow_json: "data/workflow.json"
  jobs_csv: "data/jobs.csv"
---

```{r, include = FALSE, echo = FALSE, cache = FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width=16, fig.height=12)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r, include = FALSE, echo = FALSE}
library(dplyr)
library(stringr)
library(ggplot2)
library(tidyr)
library(purrr)
library(knitr)
library(scales)
library(ggrepel)
library(wordcloud)
library(DT)
library(naniar)
library(gdata)
library(lubridate)
library(collapsibleTree)
library(ggalluvial)
library(networkD3)
library(jsonlite)
library(DT)
library(data.table)

ggplot_base <- 18
```

```{r, include = FALSE, echo = FALSE}

current_dir <- getwd()

attachments <- params$attachments_csv %>%
  read_csv() %>%
  filter(!str_detect(Type, "bvec|bval")) %>%
  filter(!(str_detect(Name, "json") & str_detect(Origin_Level, "Acquisition")))

seqinfo <- params$seqinfo_csv %>%
  read_csv()# %>%
  #filter(!is.na(series_description))

jobs <- params$jobs_csv %>%
  read_csv()

bids <- params$bids_csv %>%
  read_csv()

if(file.exists(params$workflow_json)){
  workflow <- fromJSON(params$workflow_json)
} else {
  workflow <- NA
}
```

## Project: `r params$project_name`

## Number of Subjects: `r length(unique(seqinfo$patient_id))`

## Number of Sessions: `r nrow(distinct(seqinfo, patient_id, session_id))`

---

# Sequences

Here's a list of all the sequences in `r params$project_name`:

```{r, warning=FALSE, echo=FALSE}
sequences <- seqinfo %>%
  group_by(series_description) %>%
  summarise(Freq = n()) %>%
  arrange(-Freq) %>%
  drop_na()

wordcloud(words = sequences$series_description, freq = sequences$Freq)
```

```{r, echo=FALSE}
datatable(sequences)
```

We visualise the above frequencies below:

```{r, echo = FALSE}
ggplot(sequences, aes(x = series_description, y = Freq))+
  geom_col() +
  coord_flip() +
  theme_minimal(base_size = ggplot_base) +
  labs(title = "Raw Frequencies of Sequences in the Project", x = "Sequence Name")
```

```{r, include = FALSE, echo=FALSE}
#And hence, the missingness of sequences across all the subjects in `r params$project_name`:

seq_ns <- unique(seqinfo$series_description) %>%
  na.omit() %>% as.vector()
ids <- unique(seqinfo$patient_id)
output_df <- data.frame(matrix(data = 0, ncol = length(seq_ns), nrow = length(ids)))

names(output_df) <- seq_ns

for(i in 1:length(ids)){
  
  df <- seqinfo %>%
    filter(patient_id == ids[i])
  
  
  for(row in 1:nrow(df)){
    
    
    target <- df$series_description[row]
    
    if(!is.na(target)){
      output_df[i, target] <- output_df[i, target] + 1
    }
    
  }
  
}

output_df %>%
  mutate_all(.funs = function(x) ifelse(x == 0, NA, x)) %>%
  gg_miss_var(show_pct = TRUE) +
  labs(x = "Sequence") +
  theme_minimal(base_size = ggplot_base)
```

# BIDS Curation
The tree diagram below shows how each sequence has been curated into BIDS format. The leaf at the end of each branch counts how many subjects have files that fall under each BIDS template.

```{r, echo = FALSE, message=FALSE}
seqinfo %>%
  # group_by(patient_id, session_id, series_description) %>%
  # slice(1) %>%
  # ungroup() %>%
  select(patient_id, session_id, series_id, series_description) %>%
  distinct() %>%
  filter(complete.cases(.)) %>%
  left_join(distinct(bids)) %>%
  mutate(
    bids_name = str_replace_all(Filename, "sub-[^_]+(?=_)", "\\{subject\\}"),
    bids_name = str_replace_all(bids_name, "ses-[^_]+(?=_)", "\\{session\\}")
  ) %>%
  select(series_description, Modality, bids_name, patient_id) %>%
  group_by(series_description, bids_name) %>%
  summarise(`Count` = n()) %>%
  # mutate(
  #   `Number of Subjects` = ifelse(is.na(Folder), 0, `Number of Subjects`)
  #   
  # ) %>%
  collapsibleTreeSummary(., 
    c("series_description", "bids_name"),
    attribute = "Count", root = params$project_name, width = 1000, height = 800, zoomable = TRUE
  )
```

# Gears and Jobs

There have been `r length(unique(jobs$job_id))` gears run in total, for a total runtime of `r as.character(lubridate::as.duration(sum(jobs$run_runtime_ms)/1000))`. The most commonly run gear is ``r jobs %>% group_by(gear_name) %>% summarise(n = n()) %>% arrange(-n) %>% pull(gear_name) %>% .[1]`` with a total of `r jobs %>% group_by(gear_name) %>% summarise(n = n()) %>% arrange(-n) %>% pull(n) %>% .[1]` runs. The gear with the most version increments is ``r jobs %>% group_by(gear_name) %>% summarise(n = n_distinct(gear_version)) %>% arrange(-n) %>% pull(gear_name) %>% .[1]``.

Here are the raw counts of complete gear runs, using only the most recent version and run of each gear:

```{r, echo = FALSE}
jobs %>%
  filter(run_status == "complete") %>%
  group_by(subject, session, gear_name) %>%
  arrange(subject, session, gear_name, desc(run_datetime)) %>%
  slice(1) %>%
  ungroup() %>%
  group_by(gear_name) %>%
  summarise(n = n()) %>%
  ggplot(aes(x=gear_name, y=n)) +
    geom_col() +
    theme_minimal(base_size = ggplot_base) +
    coord_flip() +
    labs(title = "Raw Count of Complete Gear Runs", x = "Gear Name") +
    NULL
```


Here are the gear completion statistics:

```{r, echo=FALSE}
jobs_plot <- jobs %>%
  # mutate(run_status = factor(run_status)) %>%
  group_by(job_id) %>%
  arrange(run_status) %>%
  filter(row_number() == 1) %>%
  ungroup() %>%
  group_by(gear_name, run_status) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n),
         perc = percent(freq, accuracy = 1),
         cumsum = cumsum(n)) %>%
  ungroup() %>%
  # mutate(perc = ifelse(freq < 0.2, "", perc)) %>%
  ggplot(aes(x=gear_name, y=n, group = run_status)) +
    geom_bar(aes(fill=run_status), stat = 'identity', position = "dodge") +
    theme_minimal(base_size = 18) +
    scale_fill_viridis_d() +
    geom_label_repel(aes(label = perc, y=n), force = 5, position = position_dodge(0.5)) +
    coord_flip() +
    labs(title = "Gear Runs & Completion Rate", x = "Gear Name") +
    NULL
    
jobs_plot
```

# Gear Runtime

Below are the runtimes of gear runs:

```{r, echo=FALSE}
jobs %>%
  mutate(run_runtime_ms = run_runtime_ms/1000/60) %>%
  #group_by(gear_name) %>%
  ggplot(aes(x=run_runtime_ms)) +
    geom_histogram(aes(fill = run_status), alpha = 0.5, bins = 25) +
    theme_minimal(base_size = 18) +
    scale_fill_viridis_d() +
    labs(title = "Gear Runtimes", x = "Runtime in Minutes") +
    facet_wrap(~gear_name, scales = "free")
```

# Workflow of Curation & Analysis Gears

Below, the Sankey Diagram illustrates the workflow of gear runs in your project `r params$project_name`. Hover over the diagram for enumerations of sessions at each node/transition.

```{r, echo = FALSE, fig.width=10, fig.height=7}
# create nodes for each gear

gear_nodes <- jobs %>%
  group_by(gear_name) %>%
  summarise(n = n()) %>%
  mutate(node = 0:(nrow(.)-1)) %>%
  select(name = gear_name, node) %>%
  as.data.frame()

# create edges

create_to_and_from <- function(df){
  
  if(nrow(df) <= 1){
    
    return(NA)
  }
  
  else{
    
    top <- 1
    bottom <- top + 1
    end <- nrow(df)
    
    from_to <- list()
    
    while(bottom <= end){
      
      #print(slice(df, top:bottom))
      row <- c(
        as.character(df[top, 'gear_name']), 
        as.character(df[bottom, 'gear_name'])
        )
      from_to[[top]] <- row
      
      top <- top + 1
      bottom <- bottom + 1
    }
    
    out_df <- do.call('rbind', from_to) %>%
      as.data.frame(stringsAsFactors = FALSE)
    
    names(out_df) <- c("from", "to")
    
    return(out_df)
  }
}

gear_edges <- jobs %>%
  filter(run_status == "complete") %>%
  select(subject, session, gear_name, run_datetime) %>%
  group_by(subject, session, gear_name) %>%
  slice(1) %>%
  ungroup() %>%
  group_by(subject, session) %>%
  arrange(subject, session, run_datetime) %>%
  mutate(index = 1:n()) %>%
  nest() %>%
  mutate(from_to = map(data, create_to_and_from)) %>%
  unnest(from_to) %>%
  #filter(!is.na(rel)) %>%
  ungroup() %>%
  group_by(from, to) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  drop_na()

gear_edges <- gear_edges %>%
  mutate(fromID = match(gear_edges$from, gear_nodes$name) - 1,
         toID = match(gear_edges$to, gear_nodes$name) - 1) %>%
  as.data.frame()

sankeyNetwork(Links = gear_edges, Nodes = gear_nodes, Source = "fromID", Target = "toID", Value = "n", fontSize = 18)
```

The Sankey Diagram Below illustrates your ideal workflow for the project, and enumerates how many sessions have been through the workflow specified in your workflow spec:

```{r, echo = FALSE, message=FALSE, fig.width=10, fig.height=7}
# get the workflow into a dataframe

stages <- names(workflow)

workflow_df <- data.frame()

for(s in stages){
  
  tempdf <- workflow[[s]] %>%
    as.data.frame(stringsAsFactors = FALSE) %>%
    mutate(stage = s, requires = ifelse(requires == "", NA, requires))
  
  workflow_df <- rbind(workflow_df, tempdf)
  
}

# > workflow_df
#             gear_name position          type          requires         stage
# 1        fw-heudiconv        1      curation                    fw-heudiconv
# 2         fmriprep-fw        3 preprocessing                        fmriprep
# 3          qsiprep-fw        4 preprocessing         ABCD_dMRI       qsiprep
# 4          qsiprep-fw        4 preprocessing ABCD_T1w_MPR_vNav       qsiprep
# 5 scale-info-uploader        2      curation                   clinical_data
# 6         qsirecon-fw        5 preprocessing                        qsirecon

# gear nodes
gear_nodes2 <- workflow_df %>%
  select(name = gear_name, node = position, group = type) %>%
  mutate(node = node-1)

# gear edges
ordered_jobs <- jobs %>%
  filter(run_status == "complete") %>%
  select(subject, session, gear_name, run_datetime) %>%
  group_by(subject, session, gear_name) %>%
  slice(1) %>%
  ungroup() %>%
  group_by(subject, session) %>%
  arrange(subject, session, run_datetime) %>%
  mutate(index = 1:n()) %>%
  ungroup()

gear_edges2 <- ordered_jobs %>%
  group_by(subject, session) %>%
  nest() %>%
  mutate(data = map(data, .f = function(x) left_join(workflow_df, x))) %>%
  mutate(data = map(data, .f = function(x) filter(x, index != 0))) %>%
  mutate(from_to = map(data, create_to_and_from)) %>%
  unnest(from_to) %>%
  #filter(!is.na(rel)) %>%
  ungroup() %>%
  group_by(from, to) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  drop_na()

gear_edges2 <- gear_edges2 %>%
  mutate(fromID = match(gear_edges2$from, gear_nodes2$name) - 1,
         toID = match(gear_edges2$to, gear_nodes2$name) - 1) %>%
  as.data.frame()

sankeyNetwork(Links = gear_edges2, Nodes = gear_nodes2, Source = "fromID", Target = "toID", Value = "n", NodeGroup = "group", fontSize = 18)
```

# Attachments

There are `r nrow(attachments)` attachments for a total of `r humanReadable(sum(attachments$Size_kb), width=4, standard = "SI")` of data. 
```{r, echo=FALSE}
attachments %>%
  ggplot(aes(x=Type)) +
  geom_bar(aes(fill = Origin_Level), alpha = 0.5) +
  theme_minimal(base_size = 18) +
  scale_fill_viridis_d() +
  labs(title = "Attachments Count")# +
  #facet_wrap(~gear_name, scales = "free")
```

---

